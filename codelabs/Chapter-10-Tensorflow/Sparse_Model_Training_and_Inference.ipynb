{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zdf8UHFSnq4r"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://github.com/EfficientDL/book/blob/main/codelabs/Chapter-10-Tensorflow/Sparse_Model_Training_and_Inference.ipynb)\n",
        "\n",
        "This is a toy colab to demonstrate pruning and sparse inference acceleration in TFLite to solve an image-classification problem with the CIFAR-10 dataset, and a vanilla CNN. We will use Tensorflow Model Optimization toolkit's pruning library to help with creating a sparse model. We will then accelerate this model using the [XNNPACK Delegate for TFLite](https://blog.tensorflow.org/2020/07/accelerating-tensorflow-lite-xnnpack-integration.html) for Android, but you should be able to see similar gains for any ARM device too. \n",
        "\n",
        "Currently the XNNPACK delegate supports a subset of operators, and for getting latency improvements there are [further restrictions](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/delegates/xnnpack/README.md#sparse-inference) on the the model graph.\n",
        "\n",
        "**Credit**: The following colab is based on the [original guide](https://www.tensorflow.org/model_optimization/guide/pruning/pruning_for_on_device_inference) authored by the TFMOT library authors with some changes that improve the model quality, simplify the flow a little bit, invoke the model and measure the latency, etc.\n",
        "\n",
        "**Caveat**: Note that this notebook might get out-of-date as the support for sparse model training and inference gets better in Tensorflow, TFLite, and XNNPACK. There might be other alternatives as well that perform better than what we listed here."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "FUdEapiG9z-0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aD6879auVeKc",
        "outputId": "6ae05238-fd2d-44b4-a543-565e07351e82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/238.9 KB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m235.5/238.9 KB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.9/238.9 KB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        " # Install the relevant packages.\n",
        " !pip install -q tensorflow\n",
        " !pip install -q tensorflow-model-optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vY1dglj4VQ-O"
      },
      "outputs": [],
      "source": [
        "import tempfile\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow import keras\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_model_optimization as tfmot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fG5idp3w6ZGM"
      },
      "source": [
        "# Dataset Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOhNok7D6ddF"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE=64\n",
        "\n",
        "def normalize(image, label):\n",
        "  \"\"\"Normalize the input to be in [-1., 1.].\"\"\"\n",
        "  return 2 * ((tf.cast(image, tf.float32) / 255.) - 0.5), label\n",
        "\n",
        "def prepare_dataset(ds, buffer_size=None):\n",
        "  \"\"\"Helper function to create the dataset objects for train / eval.\"\"\"\n",
        "  ds = ds.map(normalize, \n",
        "              num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  ds = ds.cache()\n",
        "  if buffer_size:\n",
        "    ds = ds.shuffle(buffer_size)\n",
        "  ds = ds.batch(BATCH_SIZE)\n",
        "  ds = ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "  return ds\n",
        "\n",
        "\n",
        "# Load CIFAR10 dataset.\n",
        "(ds_train, ds_val, ds_test), ds_info = tfds.load(\n",
        "  'cifar10',\n",
        "  split=['train[:90%]', 'train[90%:]', 'test'],\n",
        "  as_supervised=True,\n",
        "  with_info=True,\n",
        ")\n",
        "\n",
        "ds_train = prepare_dataset(\n",
        "    ds_train,\n",
        "    buffer_size=ds_info.splits['train'].num_examples)\n",
        "ds_val = prepare_dataset(ds_val)\n",
        "ds_test = prepare_dataset(ds_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONKJfnGw6wFS"
      },
      "source": [
        "# Define & train the dense model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NIhd27I3Vo2O"
      },
      "outputs": [],
      "source": [
        "def create_dense_model():\n",
        "  # Regularizer to prevent overfitting.\n",
        "  reg = keras.regularizers.l2(1e-5)\n",
        "\n",
        "  # Build the dense baseline model.\n",
        "  dense_model = keras.Sequential([\n",
        "    keras.layers.InputLayer(input_shape=(32, 32, 3)),\n",
        "    keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
        "    keras.layers.ZeroPadding2D(padding=1),\n",
        "    keras.layers.Conv2D(\n",
        "      filters=8,\n",
        "      kernel_size=(3, 3),\n",
        "      strides=(2, 2),\n",
        "      padding='valid', \n",
        "      kernel_regularizer=reg),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.ReLU(),\n",
        "\n",
        "    keras.layers.DepthwiseConv2D(kernel_size=(3, 3), padding='same'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.ReLU(),\n",
        "    keras.layers.Conv2D(filters=32, kernel_size=(1, 1)),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.ReLU(),\n",
        "\n",
        "    keras.layers.DepthwiseConv2D(kernel_size=(3, 3), padding='same'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.ReLU(),\n",
        "    keras.layers.Conv2D(filters=32, kernel_size=(1, 1), kernel_regularizer=reg),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.ReLU(),  \n",
        "\n",
        "    keras.layers.ZeroPadding2D(padding=1),\n",
        "    keras.layers.DepthwiseConv2D(\n",
        "        kernel_size=(3, 3), strides=(2, 2), padding='valid'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.ReLU(),\n",
        "    keras.layers.Conv2D(filters=64, kernel_size=(1, 1), kernel_regularizer=reg),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.ReLU(),\n",
        "    keras.layers.GlobalAveragePooling2D(keepdims=True),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(10)\n",
        "  ])\n",
        "  return dense_model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile and train the dense model for 10 epochs.\n",
        "INIT_LR = 1e-3\n",
        "DECAY_RATE = 0.95\n",
        "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
        "      initial_learning_rate=INIT_LR, \n",
        "      decay_steps=int(ds_info.splits['train'].num_examples / BATCH_SIZE),\n",
        "      decay_rate=DECAY_RATE)\n",
        "\n",
        "dense_model=create_dense_model()\n",
        "\n",
        "dense_model.compile(\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=keras.optimizers.Adam(lr_schedule),\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "dense_model.fit(\n",
        "  ds_train,\n",
        "  epochs=20,\n",
        "  validation_data=ds_val)\n",
        "\n",
        "# Evaluate the dense model.\n",
        "_, dense_model_accuracy = dense_model.evaluate(ds_test, verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYbAGDqURY-l",
        "outputId": "42343d72-bebf-42ba-e0e9-33f6ed8e5ace"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "704/704 [==============================] - 82s 109ms/step - loss: 1.7326 - accuracy: 0.3682 - val_loss: 1.5401 - val_accuracy: 0.4408\n",
            "Epoch 2/20\n",
            "704/704 [==============================] - 64s 91ms/step - loss: 1.4502 - accuracy: 0.4746 - val_loss: 1.4650 - val_accuracy: 0.4724\n",
            "Epoch 3/20\n",
            "704/704 [==============================] - 59s 83ms/step - loss: 1.3504 - accuracy: 0.5102 - val_loss: 1.3507 - val_accuracy: 0.5076\n",
            "Epoch 4/20\n",
            "704/704 [==============================] - 60s 86ms/step - loss: 1.2934 - accuracy: 0.5330 - val_loss: 1.3596 - val_accuracy: 0.5098\n",
            "Epoch 5/20\n",
            "704/704 [==============================] - 56s 80ms/step - loss: 1.2537 - accuracy: 0.5490 - val_loss: 1.2521 - val_accuracy: 0.5452\n",
            "Epoch 6/20\n",
            "704/704 [==============================] - 58s 82ms/step - loss: 1.2193 - accuracy: 0.5628 - val_loss: 1.2596 - val_accuracy: 0.5514\n",
            "Epoch 7/20\n",
            "704/704 [==============================] - 58s 82ms/step - loss: 1.1949 - accuracy: 0.5707 - val_loss: 1.1920 - val_accuracy: 0.5710\n",
            "Epoch 8/20\n",
            "704/704 [==============================] - 59s 83ms/step - loss: 1.1726 - accuracy: 0.5814 - val_loss: 1.2081 - val_accuracy: 0.5606\n",
            "Epoch 9/20\n",
            "704/704 [==============================] - 57s 81ms/step - loss: 1.1529 - accuracy: 0.5881 - val_loss: 1.2261 - val_accuracy: 0.5526\n",
            "Epoch 10/20\n",
            "704/704 [==============================] - 59s 84ms/step - loss: 1.1369 - accuracy: 0.5944 - val_loss: 1.1535 - val_accuracy: 0.5860\n",
            "Epoch 11/20\n",
            "704/704 [==============================] - 57s 81ms/step - loss: 1.1241 - accuracy: 0.5988 - val_loss: 1.1735 - val_accuracy: 0.5848\n",
            "Epoch 12/20\n",
            "704/704 [==============================] - 57s 82ms/step - loss: 1.1094 - accuracy: 0.6060 - val_loss: 1.1393 - val_accuracy: 0.5932\n",
            "Epoch 13/20\n",
            "704/704 [==============================] - 73s 103ms/step - loss: 1.0994 - accuracy: 0.6089 - val_loss: 1.1498 - val_accuracy: 0.5828\n",
            "Epoch 14/20\n",
            "704/704 [==============================] - 60s 86ms/step - loss: 1.0903 - accuracy: 0.6113 - val_loss: 1.1435 - val_accuracy: 0.5904\n",
            "Epoch 15/20\n",
            "704/704 [==============================] - 56s 80ms/step - loss: 1.0791 - accuracy: 0.6178 - val_loss: 1.0885 - val_accuracy: 0.6068\n",
            "Epoch 16/20\n",
            "704/704 [==============================] - 63s 89ms/step - loss: 1.0753 - accuracy: 0.6167 - val_loss: 1.1177 - val_accuracy: 0.6068\n",
            "Epoch 17/20\n",
            "704/704 [==============================] - 58s 82ms/step - loss: 1.0640 - accuracy: 0.6213 - val_loss: 1.0868 - val_accuracy: 0.6102\n",
            "Epoch 18/20\n",
            "704/704 [==============================] - 67s 95ms/step - loss: 1.0578 - accuracy: 0.6236 - val_loss: 1.0771 - val_accuracy: 0.6132\n",
            "Epoch 19/20\n",
            "704/704 [==============================] - 69s 98ms/step - loss: 1.0537 - accuracy: 0.6249 - val_loss: 1.0683 - val_accuracy: 0.6162\n",
            "Epoch 20/20\n",
            "704/704 [==============================] - 59s 84ms/step - loss: 1.0461 - accuracy: 0.6270 - val_loss: 1.0648 - val_accuracy: 0.6188\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prune the model.\n",
        "\n",
        "We start by applying the `prune_low_magnitude` wrapper on the dense model, and then fine-tune the model while slowly pruning the lowest magnitude weights. The `PruneForLatencyOnXNNPACK` pruning_policy helps us create block / structured sparsity which can then be accelerated on device. Some of the important hyper-parameters here are:\n",
        "\n",
        "1. Number of epochs to prune: If this is too small, then the model will not be fine-tuned properly, and useful weights might be pruned.\n",
        "\n",
        "2. Initial and final sparsity: Choosing a high initial sparsity might mean that useful weights are suddenly pruned. Ideally you want a reasonable ramp-up of sparsity.\n"
      ],
      "metadata": {
        "id": "vnpBBv10SAfq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFDm9eRsrNRh"
      },
      "outputs": [],
      "source": [
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "# Number of pruning epochs.\n",
        "NUM_PRUNING_EPOCHS = 5\n",
        "\n",
        "num_iterations_per_epoch = len(ds_train)\n",
        "end_step =  num_iterations_per_epoch * NUM_PRUNING_EPOCHS\n",
        "\n",
        "# Define parameters for pruning.\n",
        "pruning_params = {\n",
        "  'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(\n",
        "      initial_sparsity=0.0,\n",
        "      final_sparsity=0.75,\n",
        "      begin_step=0,\n",
        "      end_step=end_step),\n",
        "  'pruning_policy': tfmot.sparsity.keras.PruneForLatencyOnXNNPack()\n",
        "}\n",
        "\n",
        "# Try to apply pruning wrapper with pruning policy parameter.\n",
        "try:\n",
        "  model_for_pruning = prune_low_magnitude(dense_model, **pruning_params)\n",
        "except ValueError as e:\n",
        "  print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check the model for pruning wrappers.\n",
        "\n",
        "The pruning library adds in wrappers for pruning. Let's compare the output of the `summary()` methods for the two models."
      ],
      "metadata": {
        "id": "Oqe72QyAos9x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dense_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVrG42ZcpeL0",
        "outputId": "2167325f-b6aa-4a5b-9279-4a6dbe962301"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " random_flip_9 (RandomFlip)  (None, 32, 32, 3)         0         \n",
            "                                                                 \n",
            " zero_padding2d_18 (ZeroPadd  (None, 34, 34, 3)        0         \n",
            " ing2D)                                                          \n",
            "                                                                 \n",
            " conv2d_36 (Conv2D)          (None, 16, 16, 8)         224       \n",
            "                                                                 \n",
            " batch_normalization_63 (Bat  (None, 16, 16, 8)        32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_63 (ReLU)             (None, 16, 16, 8)         0         \n",
            "                                                                 \n",
            " depthwise_conv2d_27 (Depthw  (None, 16, 16, 8)        80        \n",
            " iseConv2D)                                                      \n",
            "                                                                 \n",
            " batch_normalization_64 (Bat  (None, 16, 16, 8)        32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_64 (ReLU)             (None, 16, 16, 8)         0         \n",
            "                                                                 \n",
            " conv2d_37 (Conv2D)          (None, 16, 16, 32)        288       \n",
            "                                                                 \n",
            " batch_normalization_65 (Bat  (None, 16, 16, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_65 (ReLU)             (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " depthwise_conv2d_28 (Depthw  (None, 16, 16, 32)       320       \n",
            " iseConv2D)                                                      \n",
            "                                                                 \n",
            " batch_normalization_66 (Bat  (None, 16, 16, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_66 (ReLU)             (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_38 (Conv2D)          (None, 16, 16, 32)        1056      \n",
            "                                                                 \n",
            " batch_normalization_67 (Bat  (None, 16, 16, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_67 (ReLU)             (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " zero_padding2d_19 (ZeroPadd  (None, 18, 18, 32)       0         \n",
            " ing2D)                                                          \n",
            "                                                                 \n",
            " depthwise_conv2d_29 (Depthw  (None, 8, 8, 32)         320       \n",
            " iseConv2D)                                                      \n",
            "                                                                 \n",
            " batch_normalization_68 (Bat  (None, 8, 8, 32)         128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_68 (ReLU)             (None, 8, 8, 32)          0         \n",
            "                                                                 \n",
            " conv2d_39 (Conv2D)          (None, 8, 8, 64)          2112      \n",
            "                                                                 \n",
            " batch_normalization_69 (Bat  (None, 8, 8, 64)         256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_69 (ReLU)             (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " global_average_pooling2d_9   (None, 1, 1, 64)         0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " flatten_9 (Flatten)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,882\n",
            "Trainable params: 5,466\n",
            "Non-trainable params: 416\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_for_pruning.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAuXmiYNVB2-",
        "outputId": "b2af43cd-7afd-4ead-f217-f039d8e6382e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " random_flip_9 (RandomFlip)  (None, 32, 32, 3)         0         \n",
            "                                                                 \n",
            " zero_padding2d_18 (ZeroPadd  (None, 34, 34, 3)        0         \n",
            " ing2D)                                                          \n",
            "                                                                 \n",
            " conv2d_36 (Conv2D)          (None, 16, 16, 8)         224       \n",
            "                                                                 \n",
            " batch_normalization_63 (Bat  (None, 16, 16, 8)        32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_63 (ReLU)             (None, 16, 16, 8)         0         \n",
            "                                                                 \n",
            " depthwise_conv2d_27 (Depthw  (None, 16, 16, 8)        80        \n",
            " iseConv2D)                                                      \n",
            "                                                                 \n",
            " batch_normalization_64 (Bat  (None, 16, 16, 8)        32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_64 (ReLU)             (None, 16, 16, 8)         0         \n",
            "                                                                 \n",
            " prune_low_magnitude_conv2d_  (None, 16, 16, 32)       546       \n",
            " 37 (PruneLowMagnitude)                                          \n",
            "                                                                 \n",
            " batch_normalization_65 (Bat  (None, 16, 16, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_65 (ReLU)             (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " depthwise_conv2d_28 (Depthw  (None, 16, 16, 32)       320       \n",
            " iseConv2D)                                                      \n",
            "                                                                 \n",
            " batch_normalization_66 (Bat  (None, 16, 16, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_66 (ReLU)             (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " prune_low_magnitude_conv2d_  (None, 16, 16, 32)       2082      \n",
            " 38 (PruneLowMagnitude)                                          \n",
            "                                                                 \n",
            " batch_normalization_67 (Bat  (None, 16, 16, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_67 (ReLU)             (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " zero_padding2d_19 (ZeroPadd  (None, 18, 18, 32)       0         \n",
            " ing2D)                                                          \n",
            "                                                                 \n",
            " depthwise_conv2d_29 (Depthw  (None, 8, 8, 32)         320       \n",
            " iseConv2D)                                                      \n",
            "                                                                 \n",
            " batch_normalization_68 (Bat  (None, 8, 8, 32)         128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_68 (ReLU)             (None, 8, 8, 32)          0         \n",
            "                                                                 \n",
            " prune_low_magnitude_conv2d_  (None, 8, 8, 64)         4162      \n",
            " 39 (PruneLowMagnitude)                                          \n",
            "                                                                 \n",
            " batch_normalization_69 (Bat  (None, 8, 8, 64)         256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_69 (ReLU)             (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " global_average_pooling2d_9   (None, 1, 1, 64)         0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " flatten_9 (Flatten)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,216\n",
            "Trainable params: 5,466\n",
            "Non-trainable params: 3,750\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logdir = tempfile.mkdtemp()\n",
        "\n",
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
        "]\n",
        "\n",
        "INITIAL_PRUNING_LR = 1e-4\n",
        "PRUNING_LR_DECAY_RATE = 0.95\n",
        "pruning_lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
        "  initial_learning_rate=INITIAL_PRUNING_LR, \n",
        "  decay_steps=int(ds_info.splits['train'].num_examples / BATCH_SIZE),\n",
        "  decay_rate=PRUNING_LR_DECAY_RATE)\n",
        "\n",
        "model_for_pruning.compile(\n",
        "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  optimizer=keras.optimizers.Adam(pruning_lr_schedule),\n",
        "  metrics=['accuracy'])\n",
        "\n",
        "model_for_pruning.fit(\n",
        "  ds_train,\n",
        "  epochs=NUM_PRUNING_EPOCHS,\n",
        "  validation_data=ds_val,\n",
        "  callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIRY-Cf6VCTG",
        "outputId": "aea69d93-56d1-4354-d69d-66a0b545bf8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "704/704 [==============================] - 93s 102ms/step - loss: 1.0920 - accuracy: 0.6139 - val_loss: 1.0810 - val_accuracy: 0.6136\n",
            "Epoch 2/5\n",
            "704/704 [==============================] - 80s 113ms/step - loss: 1.0826 - accuracy: 0.6161 - val_loss: 1.0911 - val_accuracy: 0.6090\n",
            "Epoch 3/5\n",
            "704/704 [==============================] - 68s 97ms/step - loss: 1.0813 - accuracy: 0.6159 - val_loss: 1.0876 - val_accuracy: 0.6062\n",
            "Epoch 4/5\n",
            "704/704 [==============================] - 58s 83ms/step - loss: 1.0845 - accuracy: 0.6162 - val_loss: 1.0870 - val_accuracy: 0.6138\n",
            "Epoch 5/5\n",
            "704/704 [==============================] - 67s 95ms/step - loss: 1.0893 - accuracy: 0.6139 - val_loss: 1.0806 - val_accuracy: 0.6080\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa49074a8e0>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verify the accuracy of the dense and pruned models.\n",
        "\n",
        "We want to ensure that the pruned model's accuracy is almost the same as the dense model."
      ],
      "metadata": {
        "id": "PMwUR0JUYrIv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the dense model.\n",
        "_, pruned_model_accuracy = model_for_pruning.evaluate(ds_test, verbose=0)\n",
        "\n",
        "print('Dense model test accuracy:', dense_model_accuracy)\n",
        "print('Pruned model test accuracy:', pruned_model_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlUXTjOwU-80",
        "outputId": "f226ce24-3154-4499-b030-98de4424ee3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dense model test accuracy: 0.6122000217437744\n",
            "Pruned model test accuracy: 0.6054999828338623\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verify that the layers are actually pruned.\n",
        "\n",
        "The pruning API will not prune all the layers (mostly Conv2D layers in the current case), and it will not prune insignificant tensors such as biases. However, we do want to ensure that it does do something."
      ],
      "metadata": {
        "id": "2E9ap8FuYvxG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWBk0k7WgNen",
        "outputId": "43246739-f3ab-4820-f862-2b7bc9f624bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrapper for layer: conv2d_37\n",
            "|-- conv2d_37/kernel:0, Num Weights: 256, Sparsity: 25%\n",
            "|-- conv2d_37/bias:0, Num Weights: 32, Sparsity: 100%\n",
            "Wrapper for layer: conv2d_38\n",
            "|-- conv2d_38/kernel:0, Num Weights: 1024, Sparsity: 25%\n",
            "|-- conv2d_38/bias:0, Num Weights: 32, Sparsity: 100%\n",
            "Wrapper for layer: conv2d_39\n",
            "|-- conv2d_39/kernel:0, Num Weights: 2048, Sparsity: 25%\n",
            "|-- conv2d_39/bias:0, Num Weights: 64, Sparsity: 100%\n"
          ]
        }
      ],
      "source": [
        "from tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper import PruneLowMagnitude\n",
        "\n",
        "for idx, layer in enumerate(model_for_pruning.layers):\n",
        "  # We will check the `PruneLowMagnitude` wrapper layers which have an\n",
        "  # associated `layer` object, which maps to the actual layer being pruned.\n",
        "  if isinstance(layer, PruneLowMagnitude):\n",
        "    print(f'Wrapper for layer: {layer.layer.name}')\n",
        "    for weight in layer.layer.weights:\n",
        "      num_weights = weight.numpy().size\n",
        "      num_nonzero_weights = np.count_nonzero(weight.numpy())\n",
        "      tensor_sparsity = num_nonzero_weights * 100. / num_weights\n",
        "      print(f'|-- {weight.name}, Num Weights: {num_weights}, '\n",
        "            f'Sparsity: {tensor_sparsity:.0f}%' )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert the models to TFLite.\n",
        "\n",
        "We convert the dense model the same way, but for the pruned model we need to strip away the pruning wrappers instead by the pruning API, and then "
      ],
      "metadata": {
        "id": "SWEQgOyXY9um"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtJRroP4vLoI",
        "outputId": "eadec858-3e68-4a69-f08b-794eb0556b4c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(dense_model)\n",
        "dense_tflite_model = converter.convert()\n",
        "\n",
        "dense_tflite_file = 'dense.tflite'\n",
        "with open(dense_tflite_file, 'wb') as f:\n",
        "  f.write(dense_tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pruned_model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(pruned_model_for_export)\n",
        "converter.optimizations = [tf.lite.Optimize.EXPERIMENTAL_SPARSITY]\n",
        "pruned_tflite_model = converter.convert()\n",
        "\n",
        "pruned_tflite_file = 'sparse.tflite'\n",
        "with open(pruned_tflite_file, 'wb') as f:\n",
        "  f.write(pruned_tflite_model)"
      ],
      "metadata": {
        "id": "j4cJ0G3zaaKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparing the size of the dense and sparse model upon compression."
      ],
      "metadata": {
        "id": "v9v_A9nn4VsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gzip\n",
        "from pathlib import Path\n",
        "\n",
        "# Create a compressed copy of input file and return its size\n",
        "def get_compressed_size_in_kbs(file):\n",
        "  path = Path(file)\n",
        "  compressed_file = path.parent / (path.name + '.gz')\n",
        "\n",
        "  with gzip.open(compressed_file, 'wb') as out:\n",
        "    with open(file, 'rb') as inp:\n",
        "      out.write(inp.read())\n",
        "      \n",
        "  return compressed_file.stat().st_size / 1024."
      ],
      "metadata": {
        "id": "toKUc0V95wZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dense_model_size_kbs = get_compressed_size_in_kbs('dense.tflite')\n",
        "sparse_model_size_kbs = get_compressed_size_in_kbs('sparse.tflite')\n",
        "\n",
        "print(f'Dense model size: {dense_model_size_kbs:.2f} KB')\n",
        "print(f'Sparse model size: {sparse_model_size_kbs:.2f} KB')\n",
        "print(f'Compression: {(dense_model_size_kbs - sparse_model_size_kbs) * 100. / dense_model_size_kbs:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3ayuLA_6K_u",
        "outputId": "afb28b06-dc1a-4ab7-e472-912d292e2004"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dense model size: 13.08 KB\n",
            "Sparse model size: 12.83 KB\n",
            "Compression: 1.89%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final latency benchmarking of the sparse model.\n",
        "We will use pre-built binaries of the `benchmark_model` binaries that Tensorflow provides, however you can also build them from source for your platform. In the colab, you can run the binary directly, but most likely you would notice than on x86 the model latency doesn't vary. However we can see the improvement in latency on Android, since the XNNPACK delegate allows acceleration on ARM.\n",
        "\n",
        "In general, we highly recommend going through the [README for the benchmark tool](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/benchmark)."
      ],
      "metadata": {
        "id": "nYOGPxiBs4TR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTZxi_r1BKGf"
      },
      "outputs": [],
      "source": [
        "!wget -q https://storage.googleapis.com/tensorflow-nightly-public/prod/tensorflow/release/lite/tools/nightly/latest/linux_x86-64_benchmark_model\n",
        "!chmod +x linux_x86-64_benchmark_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUY--bSsBLW9",
        "outputId": "48c65d22-b96c-40cd-b8a9-ee2ab1b0a72c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STARTING!\n",
            "Unconsumed cmdline flags: --use_xnnpack-true\n",
            "Log parameter values verbosely: [0]\n",
            "Min num runs: [100000]\n",
            "Min warmup runs: [100]\n",
            "Graph: [dense.tflite]\n",
            "Loaded model dense.tflite\n",
            "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
            "The input model file size (MB): 0.028156\n",
            "Initialized session in 3.939ms.\n",
            "Running benchmark for at least 100 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\n",
            "count=1762 first=443 curr=11447 min=66 max=33333 avg=283.205 std=1771\n",
            "\n",
            "Running benchmark for at least 100000 iterations and at least 1 seconds but terminate if exceeding 150 seconds.\n",
            "count=100000 first=84 curr=99 min=53 max=33503 avg=127.616 std=618\n",
            "\n",
            "Inference timings in us: Init: 3939, First inference: 443, Warmup (avg): 283.205, Inference (avg): 127.616\n",
            "Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.\n",
            "Memory footprint delta from the start of the tool (MB): init=0 overall=0\n"
          ]
        }
      ],
      "source": [
        "!./linux_x86-64_benchmark_model --graph=dense.tflite --use_xnnpack-true --warmup_runs=100 --num_runs=100000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjOVi2EIBT50",
        "outputId": "e1d96d10-ba8d-4219-e90c-e8e6c521ce5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STARTING!\n",
            "Unconsumed cmdline flags: --use_xnnpack-true\n",
            "Log parameter values verbosely: [0]\n",
            "Min num runs: [100000]\n",
            "Min warmup runs: [100]\n",
            "Graph: [sparse.tflite]\n",
            "Loaded model sparse.tflite\n",
            "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
            "The input model file size (MB): 0.021136\n",
            "Initialized session in 1.061ms.\n",
            "Running benchmark for at least 100 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\n",
            "count=8426 first=177 curr=51 min=47 max=1046 avg=58.6821 std=25\n",
            "\n",
            "Running benchmark for at least 100000 iterations and at least 1 seconds but terminate if exceeding 150 seconds.\n",
            "count=100000 first=61 curr=80 min=43 max=7697 avg=59.3359 std=54\n",
            "\n",
            "Inference timings in us: Init: 1061, First inference: 177, Warmup (avg): 58.6821, Inference (avg): 59.3359\n",
            "Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.\n",
            "Memory footprint delta from the start of the tool (MB): init=0 overall=0\n"
          ]
        }
      ],
      "source": [
        "!./linux_x86-64_benchmark_model --graph=sparse.tflite --use_xnnpack-true --warmup_runs=100 --num_runs=100000"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above two runs with the dense and sparse models might get very similar numbers, because as we said XNNPACK is optimized for ARM, and you might get a better performance improvement on device. So you can run the following commands to benchmark the model on your device."
      ],
      "metadata": {
        "id": "tHcZqahs0DEW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download the models to your machine.\n",
        "In order to benchmark on your device, let's download the dense and sparse models first to your machine. "
      ],
      "metadata": {
        "id": "zuuHDeeR1F2j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files"
      ],
      "metadata": {
        "id": "KUQgnL0k1KCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download('dense.tflite')"
      ],
      "metadata": {
        "id": "qfTYUu7J1NNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download('sparse.tflite')"
      ],
      "metadata": {
        "id": "qXfKAILa1QdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download all the required binaries, and push them to the device.\n",
        "\n",
        "For Android devices, we need the Android Debugger Bridge (ADB) that allows us to push binaries and files to it, and then run commands on it directly. You can go through the instructions [here](https://developer.android.com/studio/command-line/adb) to install ADB on your machine, if you don't have it already."
      ],
      "metadata": {
        "id": "0D5bLzZe1Tja"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once you have `adb` working on your machine, you need to download and push the right `benchmark_model` binary to the device. Note that you can build your own binary by downloading and cloning the tensorflow repository and then building the benchmark_model rule, or pick any other binary from [here](https://www.tensorflow.org/lite/performance/measurement#native_benchmark_binary).\n",
        "\n",
        "```\n",
        "wget https://storage.googleapis.com/tensorflow-nightly-public/prod/tensorflow/release/lite/tools/nightly/latest/android_aarch64_benchmark_model\n",
        "```\n",
        "\n",
        "```\n",
        "adb push android_aarch64_benchmark_model /data/local/tmp/benchmark_model\n",
        "```"
      ],
      "metadata": {
        "id": "rJk7WFV93DoY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, push the models to the device as well.\n",
        "\n",
        "```\n",
        "adb push ~/Downloads/dense.tflite /data/local/tmp/\n",
        "```\n",
        "\n",
        "```\n",
        "adb push ~/Downloads/sparse.tflite /data/local/tmp/\n",
        "```"
      ],
      "metadata": {
        "id": "v_TjyvtE5P7x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Benchmark the models on the device.\n",
        "\n",
        "We can now run the `benchmark_model` binary on the device and compare the results."
      ],
      "metadata": {
        "id": "mTnTTX_V5bPt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "$ adb shell ./data/local/tmp/benchmark_model --graph=/data/local/tmp/dense.tflite --warmup_runs=5 --num_runs=2000\n",
        "STARTING!\n",
        "Log parameter values verbosely: [0]\n",
        "Min num runs: [2000]\n",
        "Min warmup runs: [5]\n",
        "Graph: [/data/local/tmp/dense.tflite]\n",
        "Loaded model /data/local/tmp/dense.tflite\n",
        "INFO: Initialized TensorFlow Lite runtime.\n",
        "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
        "VERBOSE: Replacing 12 node(s) with delegate (TfLiteXNNPackDelegate) node, yielding 1 partitions for the whole graph.\n",
        "The input model file size (MB): 0.028008\n",
        "Initialized session in 5.401ms.\n",
        "Running benchmark for at least 5 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\n",
        "count=3380 first=729 curr=135 min=132 max=729 avg=145.822 std=33\n",
        "\n",
        "Running benchmark for at least 2000 iterations and at least 1 seconds but terminate if exceeding 150 seconds.\n",
        "count=7186 first=142 curr=140 min=132 max=1374 avg=137.33 std=18\n",
        "\n",
        "Inference timings in us: Init: 5401, First inference: 729, Warmup (avg): 145.822, Inference (avg): 137.33\n",
        "Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.\n",
        "Memory footprint delta from the start of the tool (MB): init=1.15625 overall=1.15625\n",
        "```"
      ],
      "metadata": {
        "id": "iygFb38003Xw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "$ adb shell ./data/local/tmp/benchmark_model --graph=/data/local/tmp/sparse.tflite --warmup_runs=5 --num_runs=2000\n",
        "STARTING!\n",
        "Log parameter values verbosely: [0]\n",
        "Min num runs: [2000]\n",
        "Min warmup runs: [5]\n",
        "Graph: [/data/local/tmp/sparse.tflite]\n",
        "Loaded model /data/local/tmp/sparse.tflite\n",
        "INFO: Initialized TensorFlow Lite runtime.\n",
        "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
        "VERBOSE: Replacing 15 node(s) with delegate (TfLiteXNNPackDelegate) node, yielding 1 partitions for the whole graph.\n",
        "The input model file size (MB): 0.020972\n",
        "Initialized session in 6.295ms.\n",
        "Running benchmark for at least 5 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\n",
        "count=5683 first=463 curr=80 min=78 max=686 avg=85.9257 std=26\n",
        "\n",
        "Running benchmark for at least 2000 iterations and at least 1 seconds but terminate if exceeding 150 seconds.\n",
        "count=12159 first=87 curr=80 min=78 max=1540 avg=80.4727 std=20\n",
        "\n",
        "Inference timings in us: Init: 6295, First inference: 463, Warmup (avg): 85.9257, Inference (avg): 80.4727\n",
        "Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.\n",
        "Memory footprint delta from the start of the tool (MB): init=1.21875 overall=1.21875\n",
        "```"
      ],
      "metadata": {
        "id": "MP6SgHit0dhT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "As you can see from the output above, the dense model takes ~ 137us for inference on an average, whereas the sparse model takes ~ 80us on an average. Hence we reduce the latency by an average of 42%, while keeping the accuracy the same. As the support for pruning and sparse inference improves in TFLite, and in other frameworks, you might see more sparse models being used in production."
      ],
      "metadata": {
        "id": "fydU5mby5jVr"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}